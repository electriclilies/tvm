{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prerequisites for this tutorial -- onnx resnet-18 and imagenet testing dataset\n",
    "\n",
    "# Preprocess the imagenet dataset\n",
    "import gluoncv\n",
    "from gluoncv.data import ImageNet\n",
    "from mxnet.gluon.data import DataLoader\n",
    "from mxnet.gluon.data.vision import transforms\n",
    "\n",
    "#https://github.com/onnx/models/tree/master/vision/classification/resnet\n",
    "import numpy as np\n",
    "\n",
    "def preprocess(img_data):\n",
    "    mean_vec = np.array([0.485, 0.456, 0.406])\n",
    "    stddev_vec = np.array([0.229, 0.224, 0.225])\n",
    "    norm_img_data = np.zeros(img_data.shape).astype('float32')\n",
    "    for i in range(img_data.shape[0]):  \n",
    "         # for each pixel in each channel, divide the value by 255 to get value between [0, 1] and then normalize\n",
    "        norm_img_data[i,:,:] = (img_data[i,:,:]/255 - mean_vec[i]) / stddev_vec[i]\n",
    "    return norm_img_data\n",
    "# source: https://github.com/onnx/models/blob/master/vision/classification/imagenet_preprocess.py\n",
    "\n",
    "transform_fn = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "batch_size = 2\n",
    "test_data = DataLoader(ImageNet(train=False, root='~/.mxnet/datasets/imagenet').transform_first(transform_fn), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "print(\"Finished preprocessing imagenet... \")\n",
    "\n",
    "# Write the dataset manager wrapper\n",
    "from tvm.data import DatasetManager\n",
    "\n",
    "class MxnetLoader(DatasetManager):\n",
    "    def __init__(self, data_loader, batch_size, total_batches):\n",
    "        self.data_loader = data_loader\n",
    "        self.iter = iter(data_loader)\n",
    "        self.batch_sz = batch_size\n",
    "        self.total_batches = total_batches\n",
    "        self.idx = 0\n",
    "\n",
    "    def get_next_batch(self):\n",
    "        if self.is_empty():\n",
    "            raise IndexError\n",
    "        self.idx += 1\n",
    "        data, label = next(self.iter)\n",
    "        return [data.asnumpy()], label\n",
    "\n",
    "    def batch_size(self):\n",
    "        return self.batch_sz\n",
    "\n",
    "    def num_batches(self):\n",
    "        return self.total_batches\n",
    "\n",
    "    def is_empty(self):\n",
    "        return self.idx >= self.total_batches\n",
    "\n",
    "    def reset(self):\n",
    "        self.idx = 0\n",
    "        self.iter = iter(self.data_loader)\n",
    "\n",
    "num_batches = 10\n",
    "imagenet = MxnetLoader(test_data, batch_size, num_batches)\n",
    "\n",
    "# Load the onnx model\n",
    "import onnx\n",
    "from tvm import relay\n",
    "\n",
    "onnx_model = onnx.load(\n",
    "     \"/home/lorthsmith/tvm/tutorials/quantization/resnet18-v1-7.onnx\")\n",
    "input_dict = {\"data\": [batch_size, 3, 224, 224]}\n",
    "mod, params = relay.frontend.from_onnx(onnx_model, input_dict)\n",
    "\n",
    "# Set up calibration\n",
    "import tvm\n",
    "import tvm.relay.transform.quantize as q\n",
    "\n",
    "\n",
    "cc = q.AverageMaxCalibrationCallback()\n",
    "\n",
    "quantizer = q.Quantizer(mod['main'], params, [q.AverageMaxPerChannelConv2DBiasAddPattern(cc),\n",
    "         q.AverageMaxPerChannelConv2DPattern(cc),\n",
    "         q.AverageMaxPerChannelDensePattern(cc),\n",
    "         #q.AddPattern(cc),\n",
    "         #q.MultiplyPattern(cc),\n",
    "     ],\n",
    "     skip_first=True,\n",
    "     skip_last=True,\n",
    ")\n",
    "\n",
    "calibrator = q.QuantizationCalibrator(\n",
    "     quantizer, target=\"llvm\", ctx=tvm.cpu(), dataset_manager=imagenet, show_scale_zps=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibrated_func = calibrator.calibrate()\n",
    "print(\"Calibrating..\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tvm.transform.quantize import Requantizer\n",
    "requantized_func = Requantizer().requantize(calibrated_func)\n",
    "print(\"Requantized\")\n",
    "# Build the final function\n",
    "requantized_mod = tvm.IRModule.from_expr(requantized_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tvm.transform.PassContext(opt_level=3, disabled_pass=[\"AlterOpLayout\"]):\n",
    "     lib = relay.build(mod, params=params, target=\"llvm\")\n",
    "     q_lib = relay.build(requantized_mod, params=params, target=\"llvm\")\n",
    "     c_lib = relay.build(tvm.IRModule.from_expr(calibrated_func), params=params, target=\"llvm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tvm.contrib import graph_runtime\n",
    "\n",
    "imagenet2 = MxnetLoader(test_data, batch_size, 10)\n",
    "\n",
    "q_gmod = graph_runtime.GraphModule(q_lib[\"default\"](tvm.cpu()))\n",
    "gmod = graph_runtime.GraphModule(lib[\"default\"](tvm.cpu()))\n",
    "c_gmod = graph_runtime.GraphModule(c_lib[\"default\"](tvm.cpu()))\n",
    "q_correct = 0\n",
    "c_correct = 0\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "\n",
    "while not imagenet2.is_empty():\n",
    "    images, labels = imagenet2.get_next_batch()\n",
    "    \n",
    "    q_gmod.set_input(**{'data': images[0]})\n",
    "    q_gmod.run()\n",
    "    q_out = q_gmod.get_output(0).asnumpy()\n",
    "    \n",
    "    gmod.set_input(**{'data': images[0]})\n",
    "    gmod.run()\n",
    "    out = gmod.get_output(0).asnumpy()\n",
    "\n",
    "    c_gmod.set_input(**{'data': images[0]})\n",
    "    c_gmod.run()\n",
    "    c_out = gmod.get_output(0).asnumpy()\n",
    "\n",
    "    q_predicted_labels = np.argmax(q_out, axis=1)\n",
    "    c_predicted_labels = np.argmax(c_out, axis=1)\n",
    "    predicted_labels = np.argmax(out, axis=1)\n",
    "\n",
    "    print(\"Int8 labels: \", q_predicted_labels)\n",
    "    print(\"No R Int8 labels: \", c_predicted_labels)\n",
    "    print(\"Float32 labels: \", predicted_labels)\n",
    "    print(\"Actual labels: \", labels)\n",
    "    c_correct += np.sum(c_predicted_labels == labels.asnumpy())\n",
    "    q_correct += np.sum(q_predicted_labels == labels.asnumpy())\n",
    "    correct += np.sum(predicted_labels == labels.asnumpy())\n",
    "\n",
    "    total += batch_size\n",
    "\n",
    "print(\"calibrated int8 percent correct: \", (c_correct / total) * 100)\n",
    "print(\"Int8 percent correct: \", (q_correct / total) * 100)\n",
    "print(\"Float32 percent correct: \", (correct / total) * 100)\n",
    "print(\"Difference: \", (((correct / total) * 100) - ((q_correct / total) * 100)))"
   ]
  }
 ]
}